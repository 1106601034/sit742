{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "# SIT742: Modern Data Science \n**(Week 03: Data Wrangling)**\n\n---\n- Materials in this module include resources collected from various open-source online repositories.\n- You are free to use, change and distribute this package.\n- If you found any issue/bug for this document, please submit an issue at [tulip-lab/sit742](https://github.com/tulip-lab/sit742/issues)\n\nPrepared by **SIT742 Teaching Team**\n\n---\n\n# Session 3D - Parsing Excel Files \n\n## Table of Content\n\n* Part 1. Introduction to Excel\n* Part 2. Parsing Excel with Pandas\n* Part 3. Summary\n* Part 4. Exercise\n\n\n\n---\n\n\nSo far, you have learnt how to work with data in the formats that are machine readable, \nsuch as CSV, JSON and XML. \nThe approaches used to import data in those formats are generally standard. \nHowever, not all data can easily be imported into Python or other programming languages without \na fair amount of work.\nFor example, with data stored in spreadsheets and PDFs. \nIn these circumstances, data is generated purely for human consumption.\nThe person who generated the data often tries to make it easily readable for human, \ndisregarding the importance of releasing it in a machine readable format. \n\nWe will provide some generic instructions on how to scrape data from excel files. \nYou will find that the scraping process becomes much more difficult and time-consuming. \nBut the ultimate goal stays the same, i.e., extracting data and converting it into a machine readable format. \n* * *\n\n## 1. Introduction to Excel\n\nExcel is a popular spreadsheet application originally \ndeveloped for Windows. \nYou can also find free alternatives that run on Mac OS and Linux,\nfor example, LibreOffice Calc and OpenOffice Calc can both work with Excel files.\nAn Excel document is also called a workbook. \nIt is usually saved in a file with either .xlsx extension or .xls extension, \ndepending on the Excel version you use.\nA workbook can contain multiple worksheets, each of which is a grid of cells\nwhere you keep and manipulate the data. \nThose cells are arranged in numbered rows and letter-named columns.\nExcel can display not only tabular data but also data like line graphs, histograms and charts.\nIt also provides a set of data analysis functions for statistical, engineering and financial needs.\nPresumably, most of you know what a Excel file looks like. \nIf not, please find some Excel files online and have a look or open the Excel file used in this tutorial.\n\nThere are many ways of manipulating data stored in Excel spreadsheets. \nFor instance, \n\"[Working with Excel Files in Python](http://www.python-excel.org/)\" contains pointers to \nthe best information available about working with Excel files in Python. \nThe website lists the following Python packages that deal with Excel:\n\n* `openpyxl`: Reads/writes Excel 2010 xlsx/xlsm/xltx/xltm files.\n* `xlsxwriter`: write text, numbers, formulas and hyperlinks to multiple worksheets in an Excel 2007+ XLSX file.\n* `xlrd`: Extracts data from Excel files (.xls and .xlsx, versions 2.0 onwards).\n* `xlwt`: Writes and formats Excel files compatible with Microsoft Excel versions 95 to 2003.\n* `xlutils`: Contains a set of advanced tools for manipulating Excel files (requires `xlrd` and `xlwt`).\n\nYou would need to install each separately if you want to use them;\nhowever, in this tutorial we will use Pandas `ExcelFile` class that requires `xlrd` to demonstrate how to \nparse Excel files.\n\nSome tutorials on working with Excel files that might be of your interest:\n* [Working with Excel Spreadsheets](https://automatetheboringstuff.com/chapter12/): It utilizes openyxl to read\ndata from spreadsheets. Read the following sections:\n    * Reading Excel Documents \ud83d\udcd6\n    * Project: Reading Data from a Spreadsheet \ud83d\udcd6\n* [How to read Excel files with Python (xlrd tutorial)](https://www.youtube.com/watch?v=p0DNcTnreuY): \na Youtube video on extracting data from a simple Excel file. (Optional)\n\n\nThis tutorial will use a running example to show\nyou how to extract data from Excel spreadsheets step-by-step using Pandas.\nThe example we use in this tutorial is \"[Table 2: Nutrition](http://www.unicef.org/sowc2014/numbers/documents/excel/SOWC%202014%20Stat%20Tables_Table%202.xlsx)\" from Unicef's report on \n[The State of the Worlds Children](http://www.unicef.org/sowc2014/numbers/) for 2014.\nThe download link is located at the bottom of the webpage. \nPlease download the Excel file, and store it in the same folder as where \nthe notebook located.\n\nOur task is to extract the statistic data table on the child's issues of \nunderweight, stunting, wasting and overweight prevalence in different countries.\n* * *", 
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "## 2. Parsing Excel with Pandas\nIn this section we will walk through the process of parsing our example Excel file with Pandas.\nA short tutorial on how to use Pandas `read_excel` function and the ExcelFile class  can \nbe found at Pandas [webpage on IO](http://pandas.pydata.org/pandas-docs/stable/io.html#io-excel-reader). \ud83d\udcd6  (Just read the section \"Reading Excel Files\".)\n\nBefore we start parsing our Excel file, \nwe need to first make sure the Python package `xlrd` is installed, \nas Pandas `ExcelFile` class makes use of `xlrd`. \nThe `xlrd` package can be run on Linux and Mac as well as Windows.\nHere we assume you use either Linux or Mac. \nIf you use Anaconda, you do not need to worry about this, \nas Anaconda includes the most popular Python packages for data analysis, including `xlrd`. \nOtherwise, you might need to install `xlrd` in order to run `read_excel`. \nTo install `xlrd`, you can use [pip](https://pypi.python.org/pypi/pip), \na Python package management system. \nIn your command line, simply type\n```shell\n    pip install xlrd\n```\n\nNow to start our script, \nwe need to import Pandas \nand open our Excel file by creating a Pandas `ExcelFile` object. \n    ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "!pip install wget", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "import wget\n\nlink_to_data = 'https://github.com/tulip-lab/sit742/raw/master/Jupyter/data/SOWC2014.xlsx'\n\nDataSet = wget.download(link_to_data)\n!ls", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "import pandas as pd\nexcel_data = pd.ExcelFile('SOWC2014.xlsx')\nexcel_data", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "By running the code above, we have loaded the Excel file as a Pandas' ExcelFile object into Python. \n\nAre we ready to parse our Excel File? Before starting to parse the file,\nwe probably need to ask ourselves a couple of questions. For instance,\n* How many sheets does our Excel file have?\n* Which data sheet does contain our data? What is the name of the sheet? Or what is the index of the sheet?", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Unlike CSV files, an Excel file can have multiple worksheets.\nFor example, our Excel file contains two worksheets, one contains data notes,\nand the other contains the data we want.\nIn order to get our data, we will just pull the sheet with the data we want.\n\nIf your Excel file has a couple of worksheets and you can guess the index of \nthe worksheet that contains the data you want, or you have been told from which\nworksheet you are going to extract data, you can directly use Panda's \n[`read_excel`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_excel.html#pandas.read_excel) \nfuction\n```python\n    pandas.read_excel()\n```\nThis function reads an Excel table in a given worksheet into a Pandas DataFrame, \nwhere you can start further manipulating the data.\n\nHowever, in some cases, particularly while an Excel file has a lot of worksheets,\nit might be good to view all the sheets by their names.\nSo, let's check out what the names of the sheets we have in our Excel file are:", 
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "source": "excel_data.sheet_names", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "There are two worksheets in our Excel file.\nThe one that we are looking for is \"Table 2 \". \nSo, let's read the second worksheet into a Pandas DataFrame.\nNote that there is an extra space in the worksheet name.\nWithout this space, running the following parsing code \nwill result in the following error\n```\n    XLRDError: No sheet named <'Table 2'>\n```", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "df = excel_data.parse('Table 2 ')\ndf.head()\n#df.shape", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": false
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "We have loaded the target worksheet into Python. \nThere are 322 rows and 28 columns (You can use `df.shape` to \nsee the dimensionality of the DataFrame).\n\nIf you scroll through the output, you will notice that the loaded data table is quite messy.\nThe messiness includes\n* Rows only contain missing values that are indicated by NaN in Pandas DataFrame.\n* Column heads are in three languages, i.e., English, French and Spanish.\n* Column heads in one language spread over multiple rows.\n* Country names also appear in three languages.\n* Notes shown in the original Excel file appear in rows towards the end of the data frame.\n\nRemember that our goal is to extract the data table in English. \nIt is clear that we need to further process the data frame. \nFor demonstration purpose,\nwe will try to keep the example as simple as possible,\nso we will not extract column heads here. \nInstead, if you are interested in programmatically extracting column heads, \nyou can try it by yourself. \n\n\n### Task 1 drop useless columns and rows\n\nWe will start with removing country names in French and Spanish, \nwhich corresponds to remove two columns, labeled \"Unnamed: 1\" and \"Unnamed: 2\" in our data frame.\nTo do this, we are going to use DataFrame's [`drop()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html) function, \nwhich returns a new object with labels in requested axis removed.\nWe will frequently use this function later in this section.", 
            "cell_type": "markdown", 
            "metadata": {
                "scrolled": false
            }
        }, 
        {
            "source": "df = df.drop(['Unnamed: 1', 'Unnamed: 2'], 1)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "df.shape", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "Now you should have 26 columns.\nNext we are going to remove all the rows and columns that are empty, i.e., only contains NaNs.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "df = df.dropna(0, how = 'all')\ndf = df.dropna(1, how = 'all')\ndf", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "Here we used the [`dropna`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.dropna.html) function of DataFrame. The first argument is axis (0 means row, and 1 means column),\nand the second argument indicates deleting rows/columns with all NaNs. \nWe further removed 77 rows and 1 column. \n\nThe printout shows that\nthe very first column in the data frame only contains NaNs.\nThese NaNs are row indices.\nWe cannot delete it directly.\nInstead, we are going to reset the row indices with a list of integers.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "df.index = range(len(df.index))\ndf.head(10)", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "After resetting all the row indices, and if you print out the\nfirst 15 rows using the slicing method:\n```\n    df[:15]\n```\nYou will find that the data we want starts from row index 9.\nThe first 9 rows contain column heads in three different languages.\nAs we mentioned before, to keep our script simple, we will not extract column heads here,\nrather we will delete them.\n\nSimilarly, if we print out the last 50 rows,\n```\n    df[-50:]\n```\nThe data we want ends at row 205. \nTherefore, we need to delete the first 9 rows and the \nlast 39 rows, and then reindex all the rows left.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# Delete the first 9 rows\ndf = df.drop(df.index[0:9])\n# Delete the last 39 rows\ndf = df.drop(df.index[-39:])\n# Reindex rows\ndf.index = range(len(df.index))\ndf", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "###  Task 2 Set country index\n\nSo far we have extracted all the records (or rows) for 196 countries in our Excel file. \nLet's set the country names as row indices, and reset the column labels.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "\n# Set the country names as row indices\ndf = df.set_index(df['TABLE 2. NUTRITION'].values)\n\n# Delete \"TABLE 2. NUTRITION\" column, it is now redundant.\ndf = df.drop('TABLE 2. NUTRITION', 1)\n\n# Reindex columns\ndf.columns = list(range(len(df.columns))) \ndf.head()", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "### Task 3 Tidy up all columns \n\nHowever, those records are still messy. \nAs you can see in the printout, there are a lot of NaNs, \nand cell values with both numbers and letters (e.g., \"6 x\", \" 39 x,y\",) spread over two columns.\nTherefore, we need to merge every two columns together. \n\nHow can we do that?\n\nLet us have a look at the first 10 rows and 2 columns.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "df.iloc[:10, :2]", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "A close look at the printout will give you the following patterns:\n* If the cell contains only a float or '-', the corresponding cell value in the odd-numbered column is \"NaN\". \nSee the rows labeled \"**Afghanistan**``\", \"**Albania**\", etc.\n* If the original cell contains a float and a couple of letters, the cell in the even-numbered column contains the float, and the one in the odd-numbered column contains the letters. \nSee the rows labeled \"**Algeria**\", \"**Angola**\". etc.\n\nAssume that we are going to merge the two cells containing a float and letters respectively.\nWe need a FOR loop iterating over either odd- or even-numbered columns.\nWithin this FOR loop, another FOR loop is needed to iterate over rows.\nFor each row, we check if the cell in the odd-numbered column contains NaN.\nIf it does, we then merge it with the cell in the corresponding even-numbered column on the left.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "\n# A FOR loop over odd-numbered columns\nfor col_idx in range(1, 24, 2): \n    # A For loop over rows\n    for row_idx in range(len(df)):\n        # A IF statement to check\n        #    1. If the cell value in the odd-numbered column is not NaN, then merge it the cell value in \n        #       the even-numbered column.\n        #    2. Otherwise, do nothing.\n        if not pd.isnull(df.iloc[row_idx, col_idx]):\n            df[col_idx-1][row_idx] = str(df[col_idx-1][row_idx]) + ' ' + str(df[col_idx ][row_idx])  \ndf.head()", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "The next step is to remove the odd-numbered columns in the data frame, as they are redundant now.\nTo do this, we are going to use DataFrame's `drop()` function again as follows", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "for col_idx in range(1, 24, 2): \n        df.drop(col_idx, 1, inplace = True)\ndf.head()", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "Now the data is in a pretty good shape aside from the column heads. \nWe can extract the column heads from the Excel file using either manual or programmatic method.\nHere we are going to do it manually. Considering that we are going to save results in an csv file. we will use the long name from the raw data \t\t\t\t\t\t\t\t\t\t\t\n\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "df.columns = [\"Low birthweight (%)\", \\\n              \"Early initiation of breastfeeding (%)\", \\\n              \"Exclusive breastfeeding <6 months (%)\", \\\n              \"Introduction of solid, semi-solid or soft foods 6\u20138 months (%)\", \\\n              \"Breastfeeding at age 2 (%)\", \\\n              \"Underweight (%) moderate and severe\", \\\n              \"Underweight (%) severe\", \\\n              \"Stunting (%) moderate and severe\", \\\n              \"Wasting (%) moderate and severe\",\\\n              \"Overweight (%) moderate and severe\", \\\n              \"Vitamin A supplementation, full coverage(%)\", \\\n              \"Iodized salt consumption (%)\" ]\ndf.head()", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "Finally, we have extracted the data table from our Excel file, and put it into a Pandas DataFrame.\nThe DataFrame has 197 rows and 12 columns, where rows correspond to records for individual countries\nand columns are variables (or attributes). \nOur last step is to save the data table in a CSV file.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "df.to_csv('en_final_table_2.csv')", 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "What is the problem you get? Let's check the type of some values in the DataFrame using\n```\n    type(df.iloc[i,j])\n```\nwhere i indicates row index, and j indicates column index.\nYou will find that DataFrame's `read_excel` method has parsed all strings and special characters,\nlike '-', into Unicode objects.\nIf you print the DataFrame, however, you'll get the printed version of the Unicode.\nIn contrast, printing a value in a specific location, for example, \n```python\n    df.iloc[0,0]\n```\ngives you the original Unicode,\n```\n    u'\\u2013'\n```\nTherefore, you need to specify the encoding method while saving\nthe DataFrame into a CSV file.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "df.to_csv('en_final_table_2.csv', sep=',', encoding='utf-8')", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }, 
        {
            "source": "## 3. Summary\nCompared with the three formats discussed previously, \nExcel files are not meant to be read by programming languages, but they can still be parsed with a bit more effort. \nIn this tutorial, you have learnt how to extract data from an Excel file and save\nthe extracted data in a CSV file using Pandas ExcelFile class and various\nmethods for manipulating DataFrame.\n\n## 4. Exercise \n1. In the introduction, we have mentioned a couple of Python libraries that can be \nuse to manipulate Excel files. Here we suggest that you download and install `openpyxl`,\nand try to write your own Python script to parse the same Excel file, and store the data in the\nsame format as in Section 2.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": null
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.5", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}