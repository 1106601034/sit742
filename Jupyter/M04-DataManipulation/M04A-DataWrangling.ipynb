{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kbeZa7WS_2-s"
   },
   "source": [
    "![Cloud-First](../figures/CloudFirst.png) \n",
    "\n",
    "\n",
    "# SIT742: Big Data Analytics\n",
    "**(Module: Data Manipulation)**\n",
    "\n",
    "---\n",
    "- Materials in this module include resources collected from various open-source online repositories.\n",
    "- You are free to use, change and distribute this package.\n",
    "- If you found any issue/bug for this document, please submit an issue at [tulip-lab/sit742](https://github.com/tulip-lab/sit742/issues)\n",
    "\n",
    "\n",
    "Prepared by **SIT742 Teaching Team**\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Session 4A: Data Wrangling\n",
    "\n",
    "In this session, we will learn how to use Python `pandas` package to do data wrangling.\n",
    "\n",
    "\n",
    "\n",
    "### Content\n",
    "\n",
    "\n",
    "1. Using `Pandas` to Load `CSV` Data Sets\n",
    "\n",
    "2. Structuring Data\n",
    "\n",
    "3. Data Cleaning \n",
    "\n",
    "4. Data Transformation\n",
    "\n",
    "\n",
    "\n",
    "**Note**: The data available on those service might be changing, so you need to adjust the code to accommodate those changes.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rdDCBCLn_2-1"
   },
   "source": [
    "## Part 1. Using `Pandas` to Load `CSV` Data Sets\n",
    "\n",
    "Here you will learn  how to use Pandas [read_csv()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) function to load a CSV file. Before we start importing our CSV file, it might be good for you to read [Pandas tutorial on reading CSV files](http://pandas.pydata.org/pandas-docs/stable/io.html#io-read-csv-table).\n",
    "\n",
    "If `wget` was not installed in your `Python` platform, install it first:\n",
    "\n",
    "To get started, we can import `Pandas` with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "8SfUVyvvPZsF"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5553,
     "status": "ok",
     "timestamp": 1631068844106,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -600
    },
    "id": "MF97JqHMPZsH",
    "outputId": "0e3785ca-a3af-4bf7-ebbd-bcc7e309c9d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wget\n",
      "  Downloading wget-3.2.zip (10 kB)\n",
      "Building wheels for collected packages: wget\n",
      "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9672 sha256=ef31de40082eb36982eb8865d80ec77ca1f3976731565a6fbc6645d35539e6a6\n",
      "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
      "Successfully built wget\n",
      "Installing collected packages: wget\n",
      "Successfully installed wget-3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install wget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D-h5zLd0PZsK"
   },
   "source": [
    "Suppose the `csv` data file is avilable at a URL, we use `wget` to download it to the local file system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "CIfZgHmePZsK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [..................................................................................] 312 / 312"
     ]
    }
   ],
   "source": [
    "import wget\n",
    "\n",
    "link_to_data1 = 'https://github.com/tulip-lab/sit742/raw/main/Jupyter/data/user-raw1.csv'\n",
    "DataSet1 = wget.download(link_to_data1)\n",
    "\n",
    "link_to_data2 = 'https://github.com/tulip-lab/sit742/raw/main/Jupyter/data/user-raw2.csv'\n",
    "DataSet2 = wget.download(link_to_data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PDF5d2z5PZsM"
   },
   "source": [
    "\n",
    "### Importing `CSV` data\n",
    "\n",
    "Importing `CSV` files with `Pandas` function [`read_csv()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html)  and converting the data into a form Python can understand is simple. It only takes a couple of lines of code. The imported data will be stored in Pandas `DataFrame`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 319,
     "status": "ok",
     "timestamp": 1631075326730,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -600
    },
    "id": "s_x5MR8qPZsN",
    "outputId": "292bf706-3ad9-481d-fde9-d0882b8c9414"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PID Family Name Given Name Sex  Height     Addr.\n",
      "0      0    Robinson       Alex   M    1.67       QLD\n",
      "1  11111         Lee     George   M    1.75       VIC\n",
      "2  22222      Robins        Tim   M    3.87        SA\n",
      "3  33333        Chan       Ruth   F    1.63       NSW\n",
      "4  44444       Smith        Jim   M     NaN  Victoria\n",
      "  Surname First Name Gender  Height            Addr.  target\n",
      "0     Lee     George      M   175.0         Victoria    pass\n",
      "1  Robins        Tim      M   387.0  South Australia      HD\n",
      "2    Chan       Ruth      F   163.0  New South Wales  credit\n",
      "3   Smith        Jim      M     NaN         Victoria  credit\n",
      "4  Chiang        Yin      F    65.0         Tasmania    pass\n"
     ]
    }
   ],
   "source": [
    "userdf1 = pd.read_csv(\"user-raw1.csv\", skipinitialspace=True)\n",
    "userdf2 = pd.read_csv(\"user-raw2.csv\", skipinitialspace=True)\n",
    "\n",
    "print(userdf1.head())\n",
    "print(userdf2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TkOmnCyu_2-5"
   },
   "source": [
    "## Part 2. Structuring Data\n",
    "\n",
    "\n",
    "Raw data is typically unusable in its raw state, and this is not just because of the dirty data, but sometimes because of the misformat for its intended application. Structuring is the process of taking raw data and transforming it to be more readily format for later steps, and it may involve merging multiple data sources into a single dataset with consistent or comprehensible data format. If the data comes from multiple sources, the attribute names and units of measurement may need consolidation through mapping and transformation. The specific format of your data takes will depend on the data analytics methods/tools.\n",
    "\n",
    "![User Data](https://github.com/tulip-lab/SIT742-CloudFirst/blob/develop/M04-DataManipulation/figures/DirtyData.jpg)\n",
    "\n",
    "For the datasets in above figure, we can see some issues.\n",
    "Thess issues come from data integration process, when multiple data sources were involved:\n",
    "\n",
    "- An attribute may have different names in different databases. For example, `Sex`  vs `Gender`;\n",
    "- A value of an attribute may have different measures in different sources; For example, `1.75m` vs `175cm`;\n",
    "- Different values of an attribute may have the same meaning; For example, `VIC` and `Victoria`.\n",
    "- Data Redundancy may lead to inconsistency; For example, when a dataset contains both `Date of Birth` and `Age`, inconsistency might occur.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "04ZKvRtM_2_J"
   },
   "source": [
    "### 2.1 Renaming Column Names as Per Convenience\n",
    "\n",
    "This steps involves renaming the colmns names because many column names are confusing and hard to understand.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "W_bhAPpd_2_M"
   },
   "outputs": [],
   "source": [
    "new_name = {'Sex': 'Gender',\n",
    "           'Addr.': 'Address'}\n",
    "\n",
    "userdf1.rename(columns = new_name, inplace = True)\n",
    "\n",
    "new_name = {'Surname': 'Family Name',\n",
    "           'First Name': 'Given Name',\n",
    "           'Addr.': 'Address'}\n",
    "\n",
    "userdf2.rename(columns = new_name, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o76kkUME_2_V"
   },
   "source": [
    "### 2.2 Replacing the value of the rows if needed\n",
    "\n",
    "This involves replacing the values with values more reable, such as `M` by `Male`, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 315,
     "status": "ok",
     "timestamp": 1631075411590,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -600
    },
    "id": "N5lP8CF9_2_Y",
    "outputId": "c30e59cb-181e-4264-86f0-096394b4f529"
   },
   "outputs": [],
   "source": [
    "# Replace values for the column Gender\n",
    "replace_values = {'M': 'Male', 'F': 'Female'}\n",
    "\n",
    "userdf1 = userdf1.replace({'Gender': replace_values})\n",
    "userdf2 = userdf2.replace({'Gender': replace_values})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5CVEKDN0-Uha"
   },
   "source": [
    "### 2.3 Removing one mearurement for one attribute\n",
    "This step involves choosing one measure only for `Height` attribute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Dn7j7jJO05Aa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Family Name</th>\n",
       "      <th>Given Name</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Height</th>\n",
       "      <th>Address</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lee</td>\n",
       "      <td>George</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.75</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Robins</td>\n",
       "      <td>Tim</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.87</td>\n",
       "      <td>South Australia</td>\n",
       "      <td>HD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chan</td>\n",
       "      <td>Ruth</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.63</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>credit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Smith</td>\n",
       "      <td>Jim</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>credit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chiang</td>\n",
       "      <td>Yin</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.65</td>\n",
       "      <td>Tasmania</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Enders</td>\n",
       "      <td>Robers</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Zine</td>\n",
       "      <td>Filip</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.89</td>\n",
       "      <td>Queensland</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Family Name Given Name  Gender  Height          Address  target\n",
       "0         Lee     George    Male    1.75         Victoria    pass\n",
       "1      Robins        Tim    Male    3.87  South Australia      HD\n",
       "2        Chan       Ruth  Female    1.63  New South Wales  credit\n",
       "3       Smith        Jim    Male     NaN         Victoria  credit\n",
       "4      Chiang        Yin  Female    0.65         Tasmania    pass\n",
       "5      Enders     Robers    Male     NaN         Victoria       D\n",
       "6        Zine      Filip    Male    1.89       Queensland    pass"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace height in meters instead of centimeters for the column Height\n",
    "userdf2[\"Height\"] = userdf2[\"Height\"] / 100\n",
    "\n",
    "userdf2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s5P7FONd_3CR"
   },
   "source": [
    "### Exercises\n",
    "Now, it is your turn to continue with dealing with inconvenience data.\n",
    "Please complete the code to replace the state abbreviations by its full name, such as `VIC` by `Victoria`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QYlnsbPr_3CV"
   },
   "outputs": [],
   "source": [
    "# Replace values for the column Address"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "41QZOR32W4_-"
   },
   "source": [
    "<details><summary><font color=\"blue\"><b>Click here for solutions to exercise</b></font></summary>\n",
    "```python\n",
    "replace_values = {'VIC': 'Victoria', 'NSW': 'New South Wales', \n",
    "                  'SA': 'South Australia', 'QLD': 'Queensland', \n",
    "                  'TAS': 'Tasmania'}\n",
    "\n",
    "userdf1 = userdf1.replace({'Address': replace_values})\n",
    "userdf2 = userdf2.replace({'Address': replace_values})\n",
    "\n",
    "userdf1.head()\n",
    "userdf2.head()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rBmeWNVx_3Ce"
   },
   "source": [
    "## Part 3. Data Cleaning\n",
    "\n",
    "Data Cleaning involves deleting data that’s either unnecessary or irrelevant to the project, such as PCA for dimensionality reduction, outliers removal, or identifying missing data (for example, empty cells in a spreadsheet) and either filling or removing them.\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0qUnBc7w2EtX"
   },
   "source": [
    "### 3.1 Removing the Irrelevant Columns\n",
    "\n",
    "Suppose two irrelevant columns are `PID` and `target`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>Family Name</th>\n",
       "      <th>Given Name</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Height</th>\n",
       "      <th>Address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Robinson</td>\n",
       "      <td>Alex</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.67</td>\n",
       "      <td>QLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11111</td>\n",
       "      <td>Lee</td>\n",
       "      <td>George</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.75</td>\n",
       "      <td>VIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22222</td>\n",
       "      <td>Robins</td>\n",
       "      <td>Tim</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.87</td>\n",
       "      <td>SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33333</td>\n",
       "      <td>Chan</td>\n",
       "      <td>Ruth</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.63</td>\n",
       "      <td>NSW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44444</td>\n",
       "      <td>Smith</td>\n",
       "      <td>Jim</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Victoria</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PID Family Name Given Name  Gender  Height   Address\n",
       "0      0    Robinson       Alex    Male    1.67       QLD\n",
       "1  11111         Lee     George    Male    1.75       VIC\n",
       "2  22222      Robins        Tim    Male    3.87        SA\n",
       "3  33333        Chan       Ruth  Female    1.63       NSW\n",
       "4  44444       Smith        Jim    Male     NaN  Victoria"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userdf1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "yRiH6wyuPZsU"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Family Name</th>\n",
       "      <th>Given Name</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Robinson</td>\n",
       "      <td>Alex</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lee</td>\n",
       "      <td>George</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Robins</td>\n",
       "      <td>Tim</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chan</td>\n",
       "      <td>Ruth</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Smith</td>\n",
       "      <td>Jim</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Family Name Given Name  Gender  Height\n",
       "0    Robinson       Alex    Male    1.67\n",
       "1         Lee     George    Male    1.75\n",
       "2      Robins        Tim    Male    3.87\n",
       "3        Chan       Ruth  Female    1.63\n",
       "4       Smith        Jim    Male     NaN"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_drop = ['PID', 'Address']\n",
    "\n",
    "userdf1.drop(to_drop, inplace=True, axis = 1)\n",
    "userdf1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YARLkWkHPZsU"
   },
   "source": [
    "### 3.2 Missing Data\n",
    "\n",
    "To find and fill the missing data in the dataset we will use another function. There are 2 ways to find the null values if present in the dataset. Let’s see them one by one:\n",
    "\n",
    "- Using `isnull()`: This function provides the boolean value for the complete dataset to know if any null value is present or not.\n",
    "- Using `isna().any()`: This function gives a boolean value if any null value is present or not, but it gives results column-wise, not in tabular format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "P7gpk9P-_3Cg"
   },
   "outputs": [],
   "source": [
    "# find the missing value in the dataframes\n",
    "# apply isnull() to the dataframes\n",
    "userdf1.isnull()\n",
    "userdf2.isnull()\n",
    "\n",
    "#apply isna().any() to the dataframes \n",
    "userdf1.isna().any()\n",
    "userdf2.isna().any()\n",
    "\n",
    "# drop those null value rows in userdf1\n",
    "userdf1.dropna(axis=0, inplace=True)\n",
    "\n",
    "#drop null value columns in userdf2\n",
    "userdf2.dropna(axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kAkmBKlD_3E1"
   },
   "source": [
    "### 3.3 Data Merging\n",
    "\n",
    "XXX What to do? to merge them, or to conta\n",
    "\n",
    "Merging the dataset is the process of combining two datasets in one, and line up rows based on some particular or common property for data analysis. We can do this by using the `merge()` function of the dataframe. Following is the syntax of the merge function:\n",
    "\n",
    "Left join? or just Concanate...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "0SVh16b8_3E3"
   },
   "outputs": [],
   "source": [
    "userdf = pd.merge(userdf1, userdf2, how='inner', on=None, left_on=None, \n",
    "                  right_on=None, left_index=False, right_index=False, \n",
    "                  sort=False, suffixes=('_x', '_y'), copy=True, indicator=False, \n",
    "                  validate=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CCrnP5ggPZsW"
   },
   "source": [
    "### 3.4 De-Duplicate\n",
    "\n",
    "De-Duplicate means remove all duplicate values. There is no need for duplicate values in data analysis. These values only affect the accuracy and efficiency of the analysis result. To find duplicate values in the dataset we will use a simple dataframe function i.e. `duplicated()`. Let’s see the example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 291,
     "status": "ok",
     "timestamp": 1631080167003,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -600
    },
    "id": "vGWGWRY37i1G",
    "outputId": "01bc3774-2b8d-4bd1-97d0-fc79be1c471b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1    False\n",
       "2    False\n",
       "3    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userdf.duplicated()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QvVLWFrpPZsW"
   },
   "source": [
    "This function also provides bool values for duplicate values in the dataset. \n",
    "\n",
    "If a dataset contains duplicate values it can be removed using the `drop_duplicates()` function. Following is the syntax of this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1631080169156,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -600
    },
    "id": "zvcUDctFPZsX",
    "outputId": "29b6fb3b-9e71-43ab-accc-90d2383a72c3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>Family Name</th>\n",
       "      <th>Given Name</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Height</th>\n",
       "      <th>Address</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11111</td>\n",
       "      <td>Lee</td>\n",
       "      <td>George</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.75</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22222</td>\n",
       "      <td>Robins</td>\n",
       "      <td>Tim</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.87</td>\n",
       "      <td>South Australia</td>\n",
       "      <td>HD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33333</td>\n",
       "      <td>Chan</td>\n",
       "      <td>Ruth</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.63</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>credit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55555</td>\n",
       "      <td>Chiang</td>\n",
       "      <td>Yin</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.65</td>\n",
       "      <td>Tasmania</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PID Family Name Given Name  Gender  Height          Address  target\n",
       "0  11111         Lee     George    Male    1.75         Victoria    pass\n",
       "1  22222      Robins        Tim    Male    3.87  South Australia      HD\n",
       "2  33333        Chan       Ruth  Female    1.63  New South Wales  credit\n",
       "3  55555      Chiang        Yin  Female    0.65         Tasmania    pass"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userdf.drop_duplicates(subset=None, keep='first', inplace=False, ignore_index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ib7Xcjw9PZsX"
   },
   "source": [
    "## Part 4. Data Transformation\n",
    "\n",
    "\n",
    "Data transformation is a common practice in machine learning. \n",
    "\n",
    "\n",
    "### 4.1 Using The min-max normaization maximum absolute scaling\n",
    "\n",
    "Typically, Normalization is a scaling technique in which values are shifted and rescaled so that they end up ranging between 0 and 1. It is also known as Min-Max scaling.\n",
    "\n",
    "The min-max approach (often called normalization) rescales the feature to a hard and fast range of [0,1] by subtracting the minimum value of the feature then dividing by the range. We can apply the min-max scaling in Pandas using the .min() and .max() methods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "liz_2cmgPZsX"
   },
   "outputs": [],
   "source": [
    "# copy the data\n",
    "df_min_max_scaled = userdf.copy()\n",
    "  \n",
    "# apply normalization techniques\n",
    "df_min_max_scaled['Height'] = (df_min_max_scaled['Height'] - df_min_max_scaled['Height'].min()) / \n",
    "                               (df_min_max_scaled['Height'].max() - df_min_max_scaled['Height'].min())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 295,
     "status": "ok",
     "timestamp": 1631080201664,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -600
    },
    "id": "cM-swpflPZsX",
    "outputId": "41351ff4-ae9a-4edf-be52-c71a501bec46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PID Family Name Given Name  Gender    Height          Address  target\n",
      "0  11111         Lee     George    Male  0.341615         Victoria    pass\n",
      "1  22222      Robins        Tim    Male  1.000000  South Australia      HD\n",
      "2  33333        Chan       Ruth  Female  0.304348  New South Wales  credit\n",
      "3  55555      Chiang        Yin  Female  0.000000         Tasmania    pass\n"
     ]
    }
   ],
   "source": [
    "# view normalized data\n",
    "print(df_min_max_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i_x3qi4LPZsY"
   },
   "source": [
    "### 4.2 Z-Score Standardization\n",
    "\n",
    "Standardization is another scaling technique where the values are centered around the mean with a unit standard deviation. This means that the mean of the attribute becomes zero and the resultant distribution has a unit standard deviation.\n",
    "\n",
    "The z-score method (often called standardization) transforms the info into distribution with a mean of 0 and a typical deviation of 1. Each standardized value is computed by subtracting the mean of the corresponding feature then dividing by the quality deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mIKM97RCPZsY"
   },
   "outputs": [],
   "source": [
    "# copy the data\n",
    "df_z_scaled = userdf.copy()\n",
    "  \n",
    "# apply normalization techniques\n",
    "df_z_scaled['Height'] = (df_z_scaled['Height'] - df_z_scaled['Height'].mean()) / df_z_scaled['Height'].std()    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "executionInfo": {
     "elapsed": 295,
     "status": "ok",
     "timestamp": 1631080244379,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -600
    },
    "id": "ZuMeRmCkPZsY",
    "outputId": "72b6f779-ef68-4a0e-fbb8-5317e94a2485"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>Family Name</th>\n",
       "      <th>Given Name</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Height</th>\n",
       "      <th>Address</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11111</td>\n",
       "      <td>Lee</td>\n",
       "      <td>George</td>\n",
       "      <td>Male</td>\n",
       "      <td>-0.165928</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22222</td>\n",
       "      <td>Robins</td>\n",
       "      <td>Tim</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.397481</td>\n",
       "      <td>South Australia</td>\n",
       "      <td>HD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33333</td>\n",
       "      <td>Chan</td>\n",
       "      <td>Ruth</td>\n",
       "      <td>Female</td>\n",
       "      <td>-0.254423</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>credit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55555</td>\n",
       "      <td>Chiang</td>\n",
       "      <td>Yin</td>\n",
       "      <td>Female</td>\n",
       "      <td>-0.977130</td>\n",
       "      <td>Tasmania</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PID Family Name Given Name  Gender    Height          Address  target\n",
       "0  11111         Lee     George    Male -0.165928         Victoria    pass\n",
       "1  22222      Robins        Tim    Male  1.397481  South Australia      HD\n",
       "2  33333        Chan       Ruth  Female -0.254423  New South Wales  credit\n",
       "3  55555      Chiang        Yin  Female -0.977130         Tasmania    pass"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# view normalized data   \n",
    "display(df_z_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Rbt-lB4PZsY"
   },
   "source": [
    "### 4.2 Export Dataset\n",
    "\n",
    "This is the last step of the data cleaning process. After performing all the above operations, the data is transformed into clean the dataset and it is ready to export for the next process in Data Science or Data Analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X_XHmkyQPZsZ"
   },
   "outputs": [],
   "source": [
    "df_z_scaled.to_csv('cleaned_user_data.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "s5P7FONd_3CR",
    "5kjxc5gJ_3E-"
   ],
   "name": "Copy of SIT742P04A-DataWrangling.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/tulip-lab/sit742/blob/main/Jupyter/M04-DataManipulation/M04A-DataWrangling.ipynb",
     "timestamp": 1631081268733
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
