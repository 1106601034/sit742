{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "# SIT742: Modern Data Science \n**(Assessment Task 02: Bank Marketing Data Analytics)**\n\n---\n- Materials in this module include resources collected from various open-source online repositories.\n- You are free to use, change and distribute this package.\n\nPrepared by **SIT742 Teaching Team**\n\n\n---\n\n**Project Group Information:**\n\n- Names:\n- Student IDs:\n- Emails:\n\n---", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## 1. Import Spark", 
            "cell_type": "markdown", 
            "metadata": {
                "colab_type": "text", 
                "id": "eASNvREtBU9G"
            }
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "colab_type": "code", 
                "id": "duCJfMrnGu00", 
                "colab": {}, 
                "cellView": "code"
            }, 
            "outputs": [], 
            "source": "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n!wget -q http://www-us.apache.org/dist/spark/spark-2.4.0/spark-2.4.0-bin-hadoop2.7.tgz\n!tar xf spark-2.4.0-bin-hadoop2.7.tgz\n!pip install -q findspark\n\nimport os\nos.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\nos.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.0-bin-hadoop2.7\""
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "colab_type": "code", 
                "id": "aGOo805LA-fM", 
                "colab": {}
            }, 
            "outputs": [], 
            "source": "import findspark\nfindspark.init()\nfrom pyspark.sql import SparkSession "
        }, 
        {
            "source": "## 2. Read and check data", 
            "cell_type": "markdown", 
            "metadata": {
                "colab_type": "text", 
                "id": "K7bEtO_fBZmE"
            }
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "!pip install wget  "
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import wget\n\nlink_to_data = 'https://github.com/tulip-lab/sit742/raw/master/Assessment/2019/data/bank.csv'\nDataSet = wget.download(link_to_data)\n"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "!ls"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "colab_type": "code", 
                "id": "FQ8Ts9eZBA-M", 
                "colab": {}
            }, 
            "outputs": [], 
            "source": "spark = SparkSession.builder.appName('ml-bank').getOrCreate()\n\n# Import the 'bank.csv' as a Spark dataframe and name it as df\ndf = "
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "colab_type": "code", 
                "id": "XJGWVc0yB0UA", 
                "colab": {}
            }, 
            "outputs": [], 
            "source": "# check data distribution\n# you may use printSchema() "
        }, 
        {
            "source": "## 3. Select features", 
            "cell_type": "markdown", 
            "metadata": {
                "colab_type": "text", 
                "id": "wKQMhrtFChHa"
            }
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "colab_type": "code", 
                "id": "VU5xMqN_RyM2", 
                "colab": {}
            }, 
            "outputs": [], 
            "source": "# select features ('age', 'job', 'marital', 'education', 'default', 'balance', 'housing', 'loan', 'campaign', 'pdays', 'previous', 'poutcome', 'deposit') as df2\ndf2=\n"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "colab_type": "code", 
                "id": "vwF5sqRYa_eI", 
                "colab": {}
            }, 
            "outputs": [], 
            "source": "# remove invalid rows/records using spark.sql "
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "colab_type": "code", 
                "id": "A_T8qvxzR-oI", 
                "colab": {}
            }, 
            "outputs": [], 
            "source": "# convert categorical features to numeric features  using One hot encoding, \n"
        }, 
        {
            "source": "### 3.1 normalisation", 
            "cell_type": "markdown", 
            "metadata": {
                "colab_type": "text", 
                "id": "pOqHERYJCQuC"
            }
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "colab_type": "code", 
                "id": "cfL6_sca5VwI", 
                "colab": {}
            }, 
            "outputs": [], 
            "source": "# then apply Min-Max normalisation on each attribute using MinMaxScaler  \nfrom pyspark.ml.feature import MinMaxScaler\n  "
        }, 
        {
            "source": "## 4. Unsupervised learning", 
            "cell_type": "markdown", 
            "metadata": {
                "colab_type": "text", 
                "id": "9trUY7ZgCzhW"
            }
        }, 
        {
            "source": "### 4.1 K-means", 
            "cell_type": "markdown", 
            "metadata": {
                "colab_type": "text", 
                "id": "KTQfUch2Cmmi"
            }
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "colab_type": "code", 
                "id": "dGGZI70Ohqgg", 
                "colab": {}
            }, 
            "outputs": [], 
            "source": "# Perform unsupervised learning on df2 with k-means \n# you can use whole df2 as both training and testing data, \n# evaluate the clustering result using Accuracy.  \n\nfrom pyspark.ml.clustering import KMeans\nfrom pyspark.ml.evaluation import ClusteringEvaluator\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\n "
        }, 
        {
            "source": "### 4.2 PCA", 
            "cell_type": "markdown", 
            "metadata": {
                "colab_type": "text", 
                "id": "FHom8o2KCt36"
            }
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "colab_type": "code", 
                "id": "wT4cx5uGTjmj", 
                "colab": {}
            }, 
            "outputs": [], 
            "source": "# generate a scatter plot using the first two PCA components to investigate the data distribution.\n\nfrom pyspark.ml.feature import PCA\nfrom pyspark.ml.linalg import Vectors\n "
        }, 
        {
            "source": "## 5. Supervised learning", 
            "cell_type": "markdown", 
            "metadata": {
                "colab_type": "text", 
                "id": "ulp_uILXCv4Z"
            }
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "colab_type": "code", 
                "id": "0O7tszcPfnHN", 
                "colab": {}
            }, 
            "outputs": [], 
            "source": "train, test = df2.randomSplit([0.7, 0.3], seed = 742)\nprint(\"Training Dataset Count: \" + str(train.count()))\nprint(\"Test Dataset Count: \" + str(test.count()))"
        }, 
        {
            "source": "### 5.1 LogisticRegression", 
            "cell_type": "markdown", 
            "metadata": {
                "colab_type": "text", 
                "id": "2SsHdh7YC-eN"
            }
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "colab_type": "code", 
                "id": "Vqo_ywFQYxSj", 
                "colab": {}
            }, 
            "outputs": [], 
            "source": "# Logistic Regression\n\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator "
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "colab_type": "code", 
                "id": "hANwFUzhgG83", 
                "colab": {}
            }, 
            "outputs": [], 
            "source": "# exam the coefficients"
        }, 
        {
            "source": "### 5.2 Decision tree", 
            "cell_type": "markdown", 
            "metadata": {
                "colab_type": "text", 
                "id": "evM5eiJoDHw2"
            }
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "colab_type": "code", 
                "id": "He4mlHb7hBoY", 
                "colab": {}
            }, 
            "outputs": [], 
            "source": "# Decision tree\n\nfrom pyspark.ml.classification import DecisionTreeClassifier "
        }, 
        {
            "source": "### 5.3 NaiveBayes", 
            "cell_type": "markdown", 
            "metadata": {
                "colab_type": "text", 
                "id": "CaE-Z_IlDKXF"
            }
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "colab_type": "code", 
                "id": "v2XL6I0t7irt", 
                "colab": {}
            }, 
            "outputs": [], 
            "source": "# NaiveBayes\n\nfrom pyspark.ml.classification import NaiveBayes\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\n "
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.5", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }, 
        "colab": {
            "provenance": [], 
            "collapsed_sections": [], 
            "version": "0.3.2", 
            "toc_visible": true, 
            "name": "SIT742Assignment2.ipynb"
        }
    }, 
    "nbformat": 4
}